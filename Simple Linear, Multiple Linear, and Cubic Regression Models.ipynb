{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22cab6d5-b37c-4eec-990c-97ac97c1ad8f",
   "metadata": {},
   "source": [
    "# Simple Linear, Multiple Linear, and Cubic Regression Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e78304-2b67-49aa-8955-03ca995802d7",
   "metadata": {},
   "source": [
    "## Exercise 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d3e566e-e2f1-4353-b24a-0e93a3c76d6c",
   "metadata": {},
   "source": [
    "I collect a set of data (n = 100 observations) containing a single predictor and a quantitative response. I then fit a linear regression model to the data, as well as a separate cubic regression, i.e. Y = β0 + β1X + β2X^2 + β3X^3 + ϵ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be75cb93-a6bb-4af8-a79b-da4c12debd36",
   "metadata": {},
   "source": [
    "### Excercise 4a:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92148715-0061-495f-ad9c-82bd19b8087c",
   "metadata": {},
   "source": [
    "Suppose that the true relationship between X and Y is linear, i.e. Y = β0 + β1X + ϵ. Consider the training residual sum of squares (RSS) for the linear regression, and also the training RSS for the cubic regression. Would we expect one to be lower than the other, would we expect them to be the same, or is there not enough information to tell? Justify your answer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19387ad7-a65c-477f-b8b3-117f924023dd",
   "metadata": {},
   "source": [
    "<span style=\"color: blue;\">If the relationship between X and Y is linear, then the cubic regression's training RSS would be less than the linear regression’s RSS. This is because the cubic model can always match or be better than linear fit by adjusting its extra terms. It's basically more flexible than a linear model.<span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e660ca3-af2b-4e4a-b7f0-8ba486214eec",
   "metadata": {},
   "source": [
    "### Excercise 4b:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c47b7a8c-b642-4e9f-93fd-8ed13f9551ec",
   "metadata": {},
   "source": [
    "Answer (a) using test rather than training RSS."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a7257541-2104-4349-8eef-8a697fea56a8",
   "metadata": {},
   "source": [
    "<span style=\"color: blue;\">If the relationship is actually linear, the linear regression's training RSS would probably be better because the cubic model has extra terms that aren't needed. So, it might overfit the training data, which basically  means that it could find patterns in data that don't actually exist.<span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6163a00-2431-487d-9c4f-1baef1a5d538",
   "metadata": {},
   "source": [
    "### Exercise 4c:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ebfcbe0-5742-4d08-b970-20d0b744f127",
   "metadata": {},
   "source": [
    "Suppose that the true relationship between X and Y is not linear, but we don’t know how far it is from linear. Consider the training RSS for the linear regression, and also the training RSS for the cubic regression. Would we expect one to be lower than the other, would we expect them to be the same, or is there not enough information to tell? Justify your answer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "718842f4-4ea6-489e-88c2-29870073edcc",
   "metadata": {},
   "source": [
    "<span style=\"color: blue;\">If the relationship between X and Y isn’t actually linear, then the training RSS for the cubic regression would be less than or equal to the linear regression’s RSS. This is because the cubic model can use its extra terms to essentially curve the graph to fit the data better than the linear model in the training set.<span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b818e41-37ce-46f9-9086-9093f0bb9c95",
   "metadata": {},
   "source": [
    "### Exercise 4d:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6080a7c-7469-4a12-b9fc-bb17824a3377",
   "metadata": {},
   "source": [
    "Answer (c) using test rather than training RSS."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4831a8d8-45b8-448c-a9a5-59f2ab3f750b",
   "metadata": {},
   "source": [
    "<span style=\"color: blue;\">If the true relationship isn’t linear, then we can’t really say for sure which model will do better. If the true relationship has a big curve, the cubic model might be better and have a lower test RSS. However, if the relationship is only slightly curved or if there isn't much data, the cubic model could overfit and end up doing worse than the linear model. <span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1cde33b-73e1-40a5-8138-f21fa61ac096",
   "metadata": {},
   "source": [
    "<br><br><br><br><br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c1ceb46-e18f-4f57-8146-2c46f9c4527b",
   "metadata": {},
   "source": [
    "## Exercise 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82381cb6-c624-47c5-a70d-14b406aeed4d",
   "metadata": {},
   "source": [
    "It is claimed in the text that in the case of simple linear regression of Y onto X, the R2 statistic (3.17) is equal to the square of the correlation between X and Y (3.18). Prove that this is the case. For simplicity, you may assume that x̄ = ȳ = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c39391-be7d-4672-a6e8-174a83d83454",
   "metadata": {},
   "source": [
    "<span style=\"color: blue;\">\n",
    "The slope of the regression line is equal to:\n",
    "    \n",
    "$$ b_1 = \\frac{\\sum x_i y_i}{\\sum x_i^2} $$\n",
    "\n",
    "The total variation in Y is the total sum of squares:\n",
    "\n",
    "$$ TSS = \\sum y_i^2 $$\n",
    "\n",
    "The variation in Y that can be explained by the regression line is:\n",
    "\n",
    "$$ RSS = \\sum \\hat{y}_i^2 = b_1^2 \\sum x_i^2 $$\n",
    "\n",
    "$\\hat{y}_i = b_1 x_i$ is the predicted values from the line. This shows how much of Y the line can explain.\n",
    "\n",
    "The $R^2$ statistic is the fraction of the total variation explained by the line:\n",
    "\n",
    "$$\n",
    "R^2 = \\frac{RSS}{TSS} = \\frac{b_1^2 \\sum x_i^2}{\\sum y_i^2}\n",
    "$$\n",
    "\n",
    "Now, we substitute the expression for $b_1$:\n",
    "\n",
    "$$\n",
    "R^2 = \\frac{\\left(\\sum x_i y_i\\right)^2}{\\sum x_i^2 \\cdot \\sum y_i^2}\n",
    "$$\n",
    "\n",
    "The equation for the correlation between X and Y measures how closely the points follow a straight line:\n",
    "\n",
    "$$\n",
    "r = \\frac{\\sum x_i y_i}{\\sqrt{\\sum x_i^2} \\cdot \\sqrt{\\sum y_i^2}}\n",
    "$$\n",
    "\n",
    "If we square the correlation, we get:\n",
    "\n",
    "$$\n",
    "r^2 = \\frac{\\left(\\sum x_i y_i\\right)^2}{\\sum x_i^2 \\cdot \\sum y_i^2}\n",
    "$$\n",
    "\n",
    "This is the same as $R^2$. So, we can conclude that the $R^2$ statistic is equal to the square of the correlation between X and Y.\n",
    "<span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "256b85c5-bcfa-4500-b2a3-e341fb99a10f",
   "metadata": {},
   "source": [
    "<br><br><br><br><br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690c561a-f84d-4dfc-80fe-f9794905c4c7",
   "metadata": {},
   "source": [
    "## Exercise 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cca77f6-0058-473e-beab-ab0266eed451",
   "metadata": {},
   "source": [
    "This question should be answered using the Carseats data set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b0e37f5-db41-4f42-a9cb-df8fea76736d",
   "metadata": {},
   "source": [
    "### Exercise 10a:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79827573-16fa-4f1f-a861-1d85f8b6488a",
   "metadata": {},
   "source": [
    "Fit a multiple regression model to predict **Sales** using **Price**, **Urban**, and **US**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46d76d13-2f89-4174-ab3e-8ecf3256f61b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "lm(formula = Sales ~ Price + Urban + US, data = Carseats)\n",
       "\n",
       "Residuals:\n",
       "    Min      1Q  Median      3Q     Max \n",
       "-6.9206 -1.6220 -0.0564  1.5786  7.0581 \n",
       "\n",
       "Coefficients:\n",
       "             Estimate Std. Error t value Pr(>|t|)    \n",
       "(Intercept) 13.043469   0.651012  20.036  < 2e-16 ***\n",
       "Price       -0.054459   0.005242 -10.389  < 2e-16 ***\n",
       "UrbanYes    -0.021916   0.271650  -0.081    0.936    \n",
       "USYes        1.200573   0.259042   4.635 4.86e-06 ***\n",
       "---\n",
       "Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n",
       "\n",
       "Residual standard error: 2.472 on 396 degrees of freedom\n",
       "Multiple R-squared:  0.2393,\tAdjusted R-squared:  0.2335 \n",
       "F-statistic: 41.52 on 3 and 396 DF,  p-value: < 2.2e-16\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "library(ISLR)\n",
    "data(Carseats)\n",
    "\n",
    "fit_full = lm(Sales ~ Price + Urban + US, data = Carseats)\n",
    "summary(fit_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a11a9d8-1bd8-4320-b963-c68f65978efd",
   "metadata": {},
   "source": [
    "### Exercise 10b:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0f422a-bf77-4984-8a74-a4c79209bb9c",
   "metadata": {},
   "source": [
    "Provide an interpretation of each coefficient in the model. Be careful—some of the variables in the model are qualitative!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf58d3f-a967-4a17-97a6-27f564731aa6",
   "metadata": {},
   "source": [
    "<span style=\"color: blue;\">\n",
    "Intercept (13.043): predicted Sales (in thousands) when Price = 0, Urban = No, US = No. (Intercept often has no direct practical meaning here since Price=0 is outside data range.)\n",
    "    \n",
    "\n",
    "\n",
    "Price (−0.054459): holding Urban and US fixed, increasing the price by $1 is associated with a decrease in sales of about 0.0545 thousand units (i.e. ~54.5 units). This effect is highly statistically significant (p < 2e−16). \n",
    "\n",
    "UrbanYes (−0.021916): stores located in urban areas have predicted sales about 0.0219 thousand lower than non-urban stores (≈22 units lower), holding other variables fixed — but this estimate is not statistically significant (p ≈ 0.936), so we have no evidence of a real urban effect. \n",
    "\n",
    "USYes (1.200573): stores in the US have predicted sales about 1.2006 thousand higher (≈1,200 units more) than non-US stores, with price and urban/rural fixed — this is statistically significant (p ≈ 4.86e−06)\n",
    "<span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88255def-b1fa-4b0f-b2ec-595a3aa85103",
   "metadata": {},
   "source": [
    "### Exercise 10c:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c7a199-a37e-4638-97a3-6013313a3e59",
   "metadata": {},
   "source": [
    "Write out the model in equation form, being careful to handle the qualitative variables properly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641ba3ea-b05f-4850-832e-928f6da971ec",
   "metadata": {},
   "source": [
    "<span style=\"color: blue;\">\n",
    "\n",
    "$$\n",
    "\\widehat{\\text{Sales}} = 13.043469 - 0.054459 \\times \\text{Price} - 0.021916 \\times \\text{UrbanYes} + 1.200573 \\times \\text{USYes}\n",
    "$$\n",
    "    \n",
    "<span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe6e3c4-d0e4-48c9-9902-340d22db483f",
   "metadata": {},
   "source": [
    "### Exercise 10d:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b5cb7c-b7a7-4f75-bbfd-0c341a66d798",
   "metadata": {},
   "source": [
    "For which of the predictors can you reject the null hypothesis H0: βj = 0?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e1ec957-fb3c-4ea7-8ac9-35ec2b8ed218",
   "metadata": {},
   "source": [
    "<span style=\"color: blue;\">\n",
    "Reject H0 for Price (p < 2e−16) and US (p ≈ 4.86e−06).\n",
    "    \n",
    "Fail to reject H0 for Urban (p ≈ 0.936)\n",
    "<span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b203e8a5-5aed-4952-ad12-218bab278973",
   "metadata": {},
   "source": [
    "### Exercise 10e:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7562f11-c77a-4039-9db3-3af4026ea6c9",
   "metadata": {},
   "source": [
    "On the basis of your response to the previous question, fit a smaller model that only uses the predictors for which there is evidence of association with the outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6f180b1-41c9-4671-97c7-ac8994c99bfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "lm(formula = Sales ~ Price + US, data = Carseats)\n",
       "\n",
       "Residuals:\n",
       "    Min      1Q  Median      3Q     Max \n",
       "-6.9269 -1.6286 -0.0574  1.5766  7.0515 \n",
       "\n",
       "Coefficients:\n",
       "            Estimate Std. Error t value Pr(>|t|)    \n",
       "(Intercept) 13.03079    0.63098  20.652  < 2e-16 ***\n",
       "Price       -0.05448    0.00523 -10.416  < 2e-16 ***\n",
       "USYes        1.19964    0.25846   4.641 4.71e-06 ***\n",
       "---\n",
       "Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n",
       "\n",
       "Residual standard error: 2.469 on 397 degrees of freedom\n",
       "Multiple R-squared:  0.2393,\tAdjusted R-squared:  0.2354 \n",
       "F-statistic: 62.43 on 2 and 397 DF,  p-value: < 2.2e-16\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fit_red = lm(Sales ~ Price + US, data = Carseats)\n",
    "summary(fit_red)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f5b3b7-c00b-4ff4-b859-81afe82895b3",
   "metadata": {},
   "source": [
    "### Exercise 10f:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f0e8ee5-c024-44a2-9131-b2166313982f",
   "metadata": {},
   "source": [
    "How well do the models in (a) and (e) fit the data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e5b170-18cd-4ec4-8678-1e2b1b2057b5",
   "metadata": {},
   "source": [
    "<span style=\"color: blue;\">\n",
    "Full model: (Price + Urban + US): Multiple R² ≈ 0.2393, Adj R² ≈ 0.2335, Residual SE ≈ 2.472. \n",
    "\n",
    "Reduced model: (Price + US): R² and residual SE are essentially the same (very small change) because Urban contributed almost nothing. Reduced model is preferred since Urban was not significant. (Exact R² for reduced model is nearly identical to full model; see summary(fit_red).)\n",
    "<span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d5879b9-2849-4902-930c-25e35118ee82",
   "metadata": {},
   "source": [
    "### Exercise 10g:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e2af301-af1f-472d-b5c0-e2ea2976c9bd",
   "metadata": {},
   "source": [
    "Using the model from (e), obtain 95% confidence intervals for the coefficient(s)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2f586a8-0ecb-4084-a53a-81fad3ba5865",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A matrix: 3 × 2 of type dbl</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>2.5 %</th><th scope=col>97.5 %</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>(Intercept)</th><td>11.79032020</td><td>14.27126531</td></tr>\n",
       "\t<tr><th scope=row>Price</th><td>-0.06475984</td><td>-0.04419543</td></tr>\n",
       "\t<tr><th scope=row>USYes</th><td> 0.69151957</td><td> 1.70776632</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A matrix: 3 × 2 of type dbl\n",
       "\\begin{tabular}{r|ll}\n",
       "  & 2.5 \\% & 97.5 \\%\\\\\n",
       "\\hline\n",
       "\t(Intercept) & 11.79032020 & 14.27126531\\\\\n",
       "\tPrice & -0.06475984 & -0.04419543\\\\\n",
       "\tUSYes &  0.69151957 &  1.70776632\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A matrix: 3 × 2 of type dbl\n",
       "\n",
       "| <!--/--> | 2.5 % | 97.5 % |\n",
       "|---|---|---|\n",
       "| (Intercept) | 11.79032020 | 14.27126531 |\n",
       "| Price | -0.06475984 | -0.04419543 |\n",
       "| USYes |  0.69151957 |  1.70776632 |\n",
       "\n"
      ],
      "text/plain": [
       "            2.5 %       97.5 %     \n",
       "(Intercept) 11.79032020 14.27126531\n",
       "Price       -0.06475984 -0.04419543\n",
       "USYes        0.69151957  1.70776632"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "confint(fit_red, level = 0.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0874729d-323c-4bdd-a4fd-ba262f312ae2",
   "metadata": {},
   "source": [
    "### Exercise 10h:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d21f7bb-dbdc-4e9f-beee-89eae33f23c9",
   "metadata": {},
   "source": [
    "Is there evidence of outliers or high leverage observations in the model from (e)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "08679e22-93b4-4e68-80d9-2ced42ecaf62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 standardized residuals (possible outliers):\n",
      "Observation 377 : 2.865 \n",
      "Observation 51 : -2.811 \n",
      "Observation 69 : 2.623 \n",
      "Observation 26 : 2.581 \n",
      "Observation 210 : -2.563 \n",
      "\n",
      "Top 5 leverage values (possible high-leverage points):\n",
      "Observation 43 : 0.043 \n",
      "Observation 175 : 0.03 \n",
      "Observation 166 : 0.029 \n",
      "Observation 126 : 0.026 \n",
      "Observation 368 : 0.024 \n",
      "\n",
      "Top 5 Cook's distance values (influential points):\n",
      "Observation 26 : 0.0261 \n",
      "Observation 368 : 0.0243 \n",
      "Observation 50 : 0.0228 \n",
      "Observation 317 : 0.0205 \n",
      "Observation 166 : 0.0198 \n"
     ]
    }
   ],
   "source": [
    "resid_vals = rstandard(fit_red)\n",
    "top5_resid = order(abs(resid_vals), decreasing = TRUE)[1:5]\n",
    "\n",
    "cat(\"Top 5 standardized residuals (possible outliers):\\n\")\n",
    "for (i in top5_resid) {\n",
    "  cat(\"Observation\", i, \":\", round(resid_vals[i], 3), \"\\n\")\n",
    "}\n",
    "\n",
    "\n",
    "lev_vals = hatvalues(fit_red)\n",
    "top5_lev = order(lev_vals, decreasing = TRUE)[1:5]\n",
    "\n",
    "cat(\"\\nTop 5 leverage values (possible high-leverage points):\\n\")\n",
    "for (i in top5_lev) {\n",
    "  cat(\"Observation\", i, \":\", round(lev_vals[i], 3), \"\\n\")\n",
    "}\n",
    "\n",
    "\n",
    "cook_vals = cooks.distance(fit_red)\n",
    "top5_cook = order(cook_vals, decreasing = TRUE)[1:5]\n",
    "\n",
    "cat(\"\\nTop 5 Cook's distance values (influential points):\\n\")\n",
    "for (i in top5_cook) {\n",
    "  cat(\"Observation\", i, \":\", round(cook_vals[i], 4), \"\\n\")\n",
    "}\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
